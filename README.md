# DB_Electric â€“ Stromkosten-Analysesystem

**3. Semester Datenbanken WDS24A â€“ Capstone Projekt**

---

## ğŸ“‹ ProjektÃ¼bersicht

Dieses Projekt entwickelt ein Data-Engineering-System zur Analyse von Stromkosten in einem produzierenden Unternehmen mit 5 Standorten in Deutschland. Das System beantwortet drei datengetriebene Kernfragen fÃ¼r unterschiedliche Stakeholder.

**Technologien:** Python 3.12+, pandas, SQLite, uv

---

## ğŸ¯ Die drei Kernfragen

### Frage 1: StromkostenintensitÃ¤t (Finanz-Perspektive)

**Kernfrage:** Welche Standorte wiesen im Zeitraum Q1â€“Q4 2024 strombezogene StÃ¼ckkosten (â‚¬/Einheit) auf, die mehr als 15% Ã¼ber dem unternehmensweiten Durchschnitt lagen?

| **Aspekt** | **Spezifikation** |
|---|---|
| **Stakeholder** | CFO (Chief Financial Officer) |
| **Entscheidung** | Priorisierung von Modernisierungsbudgets fÃ¼r "AusreiÃŸer"-Standorte. |
| **Risiko** | Fehlallokation von Investitionsbudget; Ineffizienzen werden Ã¼bersehen. |
| **MessgrÃ¶ÃŸen** | Stromkosten pro Einheit (â‚¬/StÃ¼ck), Abweichung vom Durchschnitt (%). |
| **Zeitfenster** | 12 Monate (Q1â€“Q4 2024), quartalsweise aggregiert. |
| **Frequenz** | Quartalsweise (Reporting). |
| **Erfolgskriterium** | Streuung der StÃ¼ckkosten zwischen Standorten < 10%. |
| **BenÃ¶tigte Daten** | Produktionsmengen, Energieverbrauch, Vertragspreise (`fact_production`, `fact_energy`). |

### Frage 2: Lastspitzen-Analyse (Operations-Perspektive)

**Kernfrage:** Welche Produktionslinien und Schichten sind die systematischen Treiber fÃ¼r die Ãœberschreitung der 500kW-Lastgrenze? (Schwellenwert (>500kW) ist der AuslÃ¶ser fÃ¼r Kosten)

| **Aspekt** | **Spezifikation** |
|---|---|
| **Stakeholder** | Produktionsleiter / COO |
| **Entscheidung** | Optimierung der Schichtplanung und Lastverteilung zur Vermeidung von SpitzenlastgebÃ¼hren. |
| **Risiko** | Hohe Netzentgelte durch unkontrollierte Leistungsspitzen; ProduktionsausfÃ¤lle durch Ãœberlastung. |
| **MessgrÃ¶ÃŸen** | Anzahl Lastspitzen (>500 kW), Durchschnitts-/Max-Leistung (kW), Auslastung (%). |
| **Zeitfenster** | 3 Monate (Q4 2024: Oktoberâ€“Dezember), pro Schicht aggregiert. |
| **Frequenz** | Monatlich (Reporting). |
| **Erfolgskriterium** | Linien mit >6 Spitzen pro Quartal identifiziert und MaÃŸnahmen eingeleitet. |
| **BenÃ¶tigte Daten** | Leistungsmesswerte, Produktionsauslastung (`fact_energie`, `fact_produktion`, `dim_zeit`, `dim_linie`, `dim_standort`). |

### Frage 3: Lieferantenpreis-Analyse (Einkaufs-Perspektive)

**Kernfrage:** Wie hoch ist der effektive Preisaufschlag (Premium) unserer Lieferanten gegenÃ¼ber dem Spotmarkt-Benchmark im Zeitraum von 2023 - 2024?

| **Aspekt** | **Spezifikation** |
|---|---|
| **Stakeholder** | CFO / Einkaufsleitung |
| **Entscheidung** | Auswahl und Neuverhandlung von LieferantenvertrÃ¤gen basierend auf Preis-Risiko-VerhÃ¤ltnis. |
| **Risiko** | ÃœberhÃ¶hte Beschaffungskosten; unkalkulierbare Preisschwankungen bei volatilen Lieferanten. |
| **MessgrÃ¶ÃŸen** | Durchschnittspreis (â‚¬/kWh), Aufschlag vs. Spotmarkt (â‚¬ und %), VolatilitÃ¤t, Variationskoeffizient (%). |
| **Zeitfenster** | 24 Monate (2023â€“2024), quartalsweise aggregiert. |
| **Frequenz** | Quartalsweise (Reporting). |
| **Erfolgskriterium** | Lieferanten mit Variationskoeffizient <10% und Aufschlag <15% vs. Spotmarkt identifiziert. |
| **BenÃ¶tigte Daten** | Lieferantenpreise, Spotmarktpreise (`fact_lieferantenpreis`, `fact_spotmarkt`, `dim_zeit`, `dim_lieferant`). |

---

## ğŸ“Š Datenmodell

### ER-Diagramm (Star Schema)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  dim_zeit    â”‚
                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                    â”‚ zeit_id (PK) â”‚
                    â”‚ datum        â”‚
                    â”‚ jahr         â”‚
                    â”‚ quartal      â”‚
                    â”‚ monat        â”‚
                    â”‚ kw           â”‚
                    â”‚ stunde       â”‚
                    â”‚ schicht      â”‚
                    â”‚ ist_werktag  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                      â”‚                      â”‚
    â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚fact_energie â”‚    â”‚ fact_produktion â”‚    â”‚  fact_spotmarkt  â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ energie_id  â”‚    â”‚ produktion_id   â”‚    â”‚ spot_id          â”‚
â”‚ zeit_id(FK) â”‚    â”‚ zeit_id (FK)    â”‚    â”‚ zeit_id (FK)     â”‚
â”‚ linie_id(FK)â”‚    â”‚ linie_id (FK)   â”‚    â”‚ preis_eur_kwh    â”‚
â”‚ vertrag_id  â”‚    â”‚ menge_gut       â”‚    â”‚ marktgebiet      â”‚
â”‚ verbrauch   â”‚    â”‚ menge_ausschuss â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ leistung_maxâ”‚    â”‚ auslastung_pct  â”‚
â”‚ messstatus  â”‚    â”‚ laufzeit_min    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚fact_lieferantenpreisâ”‚
       â”‚                    â”‚             â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
       â”‚                    â”‚             â”‚ preis_id           â”‚
       â–¼                    â–¼             â”‚ zeit_id (FK)       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ lieferant_id (FK)  â”‚
â”‚  dim_linie   â”‚    â”‚ dim_standort â”‚      â”‚ preis_eur_kwh      â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ linie_id(PK) â”‚â”€â”€â”€â–¶â”‚standort_id(PK)â”‚               â”‚
â”‚ standort_id  â”‚    â”‚ standort_code â”‚               â–¼
â”‚ linie_code   â”‚    â”‚ standort_name â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ technologie  â”‚    â”‚ land          â”‚      â”‚  dim_lieferant   â”‚
â”‚ nennleistung â”‚    â”‚ region        â”‚      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚lieferant_id (PK) â”‚
                            â”‚              â”‚ lieferant_code   â”‚
                            â–¼              â”‚ lieferant_name   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ typ              â”‚
                    â”‚ dim_vertrag  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
                    â”‚vertrag_id(PK)â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚lieferant_id  â”‚   n:m Beziehung
                    â”‚standort_id   â”‚
                    â”‚gueltig_ab    â”‚
                    â”‚gueltig_bis   â”‚
                    â”‚grundpreis    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Modellierungsentscheidungen

| Entscheidung | BegrÃ¼ndung |
|--------------|------------|
| **Star Schema** | Optimiert fÃ¼r analytische Queries mit vielen JOINs |
| **n:m Ã¼ber `dim_vertrag`** | Ein Standort kann mehrere Lieferanten haben (zeitlich begrenzt), ein Lieferant beliefert mehrere Standorte |
| **`dim_zeit` auf 15-Min-Basis** | Entspricht der GranularitÃ¤t von Strompreisen (SMARD-Daten) |
| **`messstatus` in `fact_energie`** | ErmÃ¶glicht NULL-Handling und DatenqualitÃ¤tsanalysen |

### TabellenÃ¼bersicht

| Tabelle | Zeilen | Beschreibung |
|---------|-------:|--------------|
| `dim_zeit` | ~70.000 | 15-Min-Intervalle 2023â€“2024 |
| `dim_standort` | 5 | Produktionsstandorte in DE |
| `dim_linie` | 15 | Produktionslinien (3 pro Standort) |
| `dim_lieferant` | 4 | Stromlieferanten |
| `dim_vertrag` | 6 | LiefervertrÃ¤ge |
| `fact_energie` | ~962.000 | Energieverbrauch pro Intervall/Linie |
| `fact_produktion` | ~28.000 | Produktionsmengen pro Schicht/Linie |
| `fact_spotmarkt` | ~70.000 | Echte SMARD-GroÃŸhandelspreise |
| `fact_lieferantenpreis` | ~281.000 | Lieferantenpreise (abgeleitet) |
| **Gesamt** | **~1.400.000** | Large Dataset |

---

## ğŸ”§ Installation & AusfÃ¼hrung

```bash
# AbhÃ¤ngigkeiten installieren (mit uv)
uv sync

# Gesamtes Projekt ausfÃ¼hren (Generierung â†’ Laden â†’ Queries â†’ Visualisierung)
uv run python main.py

# Einzelne Schritte:
uv run python src/data_generation/generate_all.py   # Daten generieren
uv run python src/data_loading/load_to_sqlite.py    # In SQLite laden
uv run python src/queries/run_queries.py            # Queries ausfÃ¼hren
```

### Benchmark

```bash
# SQL-Performance messen (3 Iterationen)
uv run python src/benchmark.py -i 3

# Mit frischer Datenbank (Reset)
uv run python src/benchmark.py -r -i 5

# Optionen:
#   -r, --reset       Datenbank neu erstellen
#   -i, --iterations  Anzahl DurchlÃ¤ufe (Standard: 3)
#   -v, --verbose     Detaillierte Ausgabe
```

Ergebnisse werden in `output/benchmarks/` gespeichert (JSON, CSV).

---

## ğŸ“ Projektstruktur

```
DB_Electric/
â”œâ”€â”€ main.py                          # Orchestriert alle Schritte
â”œâ”€â”€ pyproject.toml                   # Projektdefinition (uv)
â”œâ”€â”€ uv.lock                          # Lockfile
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ create_tables.sql            # DDL-Schema
â”‚   â”œâ”€â”€ stromkosten.db               # SQLite-Datenbank
â”‚   â”œâ”€â”€ grosshandelpreise_*.csv      # SMARD-Quelldaten
â”‚   â””â”€â”€ generated/                   # Generierte CSV-Dateien
â”‚       â”œâ”€â”€ dim_*.csv
â”‚       â””â”€â”€ fact_*.csv
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ frage*_*.png                 # Visualisierungen
â”‚   â””â”€â”€ benchmarks/                  # Benchmark-Ergebnisse
â”‚       â”œâ”€â”€ benchmark_*.json
â”‚       â””â”€â”€ benchmark_*.csv
â””â”€â”€ src/
    â”œâ”€â”€ benchmark.py                 # Performance-Messung
    â”œâ”€â”€ data_generation/             # Python-Generatoren
    â”‚   â”œâ”€â”€ generate_all.py
    â”‚   â”œâ”€â”€ dim_*.py
    â”‚   â””â”€â”€ fact_*.py
    â”œâ”€â”€ data_loading/
    â”‚   â””â”€â”€ load_to_sqlite.py        # CSV â†’ SQLite Import
    â””â”€â”€ queries/
        â”œâ”€â”€ run_queries.py           # Query-Runner
        â”œâ”€â”€ visualize.py             # Chart-Generierung
        â”œâ”€â”€ setup_indexes.sql        # Benchmark-Indizes
        â”œâ”€â”€ frage1.sql               # StromkostenintensitÃ¤t (Naive)
        â”œâ”€â”€ frage1_optimized.sql     # StromkostenintensitÃ¤t (CTE)
        â”œâ”€â”€ frage2.sql               # Lastspitzen (Naive)
        â”œâ”€â”€ frage2_optimized.sql     # Lastspitzen (Index)
        â”œâ”€â”€ frage3.sql               # Lieferantenpreise (UNION)
        â””â”€â”€ frage3_optimized.sql     # Lieferantenpreise (CTE)
```

---

## ğŸ“ˆ SQL-Queries

### Frage 1: StromkostenintensitÃ¤t

**JOIN-Pfad:** `fact_energie` â†’ `dim_zeit` â†’ `dim_linie` â†’ `dim_standort` (+ Produktion + Preise)

```sql
-- Vereinfachte Struktur
WITH energie_pro_standort AS (...),
     produktion_pro_standort AS (...),
     preis_pro_standort AS (...),
     standort_kosten AS (...),
     durchschnitt AS (...)
SELECT standort_name, kosten_pro_stueck, abweichung_pct
FROM standort_kosten
WHERE abweichung_pct > 15;
```

**Performance:** Siehe Benchmark-Sektion unten.

### Frage 2: Lastspitzen

**JOIN-Pfad:** `fact_energie` â†’ `dim_zeit` â†’ `dim_linie` â†’ `dim_standort`

```sql
WITH lastspitzen AS (
    SELECT ... WHERE leistung_max_kw > 500
),
auslastung AS (...)
SELECT standort_name, linie_code, COUNT(*) AS anzahl_spitzen
HAVING COUNT(*) > 6;
```

### Frage 3: Lieferantenpreise

**JOIN-Pfad:** `fact_lieferantenpreis` â†’ `dim_zeit` â†’ `dim_lieferant` (+ Spotmarkt)

```sql
WITH lieferant_quartalspreise AS (...),
     spot_quartalspreise AS (...),
     volatilitaet AS (
         SELECT SQRT(AVG(xÂ²) - AVG(x)Â²) AS volatilitaet ...
     )
SELECT lieferant_name, avg_preis, aufschlag_pct, volatilitaet;
```

---

## âš¡ Performance-Benchmark

Vergleich zwischen naiven und optimierten SQL-Queries (30 Iterationen, SQLite):

| Query | Naive | Optimiert | Speedup | Optimierung |
|-------|------:|----------:|--------:|-------------|
| Frage 1 (Stromkosten) | 580 ms | 549 ms | **1.1x** | CTE statt korrelierte Subquery |
| Frage 2 (Lastspitzen) | 41 ms | 38 ms | **1.1x** | Partieller Index (wenig Effekt bei Star-Schema) |
| Frage 3 (Lieferanten) | 338 ms | 177 ms | **1.9x** | CTE statt UNION ALL (DRY-Prinzip) |

### Optimierungsstrategien

**Frage 1 â€“ CTE statt Subquery:**
```sql
-- Naive: Korrelierte Subquery (5x Nested Loop)
SELECT ..., (SELECT SUM(...) WHERE standort_id = s.id) FROM ...

-- Optimiert: Einmalige Aggregation, dann JOIN
WITH prod_agg AS (SELECT standort_id, SUM(...) GROUP BY standort_id)
SELECT ... FROM energie JOIN prod_agg ON ...
```

**Frage 3 â€“ CTE statt UNION:**
```sql
-- Naive: dim_zeit wird 2x gescannt (je 70k Zeilen)
SELECT ... FROM lieferanten JOIN dim_zeit WHERE jahr IN (2023,2024)
UNION ALL
SELECT ... FROM spotmarkt JOIN dim_zeit WHERE jahr IN (2023,2024)

-- Optimiert: dim_zeit nur 1x scannen
WITH relevante_zeit AS (SELECT zeit_id FROM dim_zeit WHERE jahr IN (2023,2024))
SELECT ... FROM lieferanten JOIN relevante_zeit ...
```

---

## âš ï¸ DatenqualitÃ¤t & NULL-Handling

### NULL-Werte in `fact_energie`

Die Spalte `messstatus` enthÃ¤lt drei Werte:
- `OK` (95%): GÃ¼ltige Messung
- `FEHLER` (5%): Defekter Sensor oder fehlende Werte

**Beispiel aus den Queries:**
```sql
-- Frage 1: Nur valide Messungen verwenden
WHERE e.messstatus = 'OK'

-- Frage 2: Nur valide Messungen
WHERE e.messstatus = 'OK'
```

**Relevanz:** In echten Systemen kÃ¶nnen Sensorfehler, NetzausfÃ¤lle oder Wartungsfenster zu NULL-Werten fÃ¼hren. Ohne korrekte Filterung wÃ¼rden Aggregationen verfÃ¤lscht (z.B. falscher Durchschnitt durch Division mit weniger Zeilen).

---

## ğŸ†š MongoDB-Vergleich (Theoretisch)

**Beispielfrage:** â€Wie viele Eskalations-Events pro Projekt gab es im letzten Monat â€“ gruppiert nach Typ?"

### JSON-Beispielobjekt

```json
{
  "_id": "evt_20241205_001",
  "projekt_id": "PRJ-2024-042",
  "timestamp": "2024-12-05T14:32:00Z",
  "typ": "LASTSPITZE",
  "details": {
    "linie_id": "MUC-L2",
    "peak_kw": 612.5,
    "grenzwert_kw": 500,
    "dauer_sekunden": 45
  },
  "eskalation": {
    "stufe": 2,
    "benachrichtigt": ["ops@firma.de", "coo@firma.de"],
    "status": "acknowledged"
  }
}
```

### Warum SQL schwierig ist

Verschachtelte Objekte wie `details` und `eskalation` erfordern in SQL entweder zusÃ¤tzliche Tabellen (n:m) oder JSON-Spalten, was die Abfrage verkompliziert und Performance-Probleme bei hÃ¤ufigen Schema-Ã„nderungen verursacht.

### Warum MongoDB geeigneter wÃ¤re

Dokumentenorientierte Speicherung erlaubt flexible Event-Strukturen, native Array-Operationen fÃ¼r `benachrichtigt[]`, und die Aggregation Pipeline ist fÃ¼r Event-Gruppierungen optimiert.

### JSON-Schema

```json
{
  "bsonType": "object",
  "required": ["projekt_id", "timestamp", "typ"],
  "properties": {
    "typ": { "enum": ["LASTSPITZE", "SENSOR_AUSFALL", "PREIS_SPIKE"] },
    "eskalation.stufe": { "bsonType": "int", "minimum": 1, "maximum": 3 }
  }
}
```

---

## ğŸ“Š Executive Summary

### Kernfragen & Erkenntnisse

| Frage | Insight |
|-------|---------|
| **StromkostenintensitÃ¤t** | Hamburg-Harburg liegt konstant >15% Ã¼ber dem Durchschnitt durch niedrigere Produktionseffizienz bei hÃ¶herem Verbrauch |
| **Lastspitzen** | MÃ¼nchen-Garching (MUC-L1, MUC-L2) verursacht 3Ã— mehr Lastspitzen â€“ korreliert mit SpÃ¤tschicht-Auslastung |
| **Lieferantenpreise** | Spotmarkt-Direkt bietet gÃ¼nstigste Preise, aber hÃ¶chste VolatilitÃ¤t (5%); Naturstrom ist 20% teurer, aber stabilste Preise |

### Limitierungen

- Keine echten Produktionsdaten (synthetisch generiert)
- SQLite ohne echte Concurrent-Workload-Tests
- Keine saisonalen Muster in Produktion modelliert

### Empfehlung

1. **Hamburg:** Energieaudit durchfÃ¼hren, Maschinen-Retrofit prÃ¼fen
2. **MÃ¼nchen:** Lastmanagement fÃ¼r SpÃ¤tschicht implementieren (Load Shifting)
3. **Einkauf:** Hybrid-Modell evaluieren â€“ 70% Festpreis (E.ON), 30% Spotmarkt fÃ¼r FlexibilitÃ¤t

---

## ğŸ‘¥ Team

WDS24A â€“ Datenbanken, 3. Semester
